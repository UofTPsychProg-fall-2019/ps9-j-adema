M <- lmer(log(seek_resp.rt)~rt_bins*basic+(1|participant),data=median_rt_bins)
View(median_rt_bins)
View(median_rt_bins)
M <- lmer(log(medianRT)~rt_bins*basic+(1|participant),data=median_rt_bins)
summary(M)
plot(ggpredict(M,terms=c('median_rt_bins','basic')))
View(median_rt_bins)
M <- lmer(log(medianRT)~rt_bins*basic+(1|participant),data=median_rt_bins)
summary(M)
plot(ggpredict(M,terms=c('rt_bins','basic')))
M <- lmer(log(seek_resp.rt)~exp_pos*basic+(1|participant),data=clean_df)
summary(M)
plot(ggpredict(M,terms=c('exp_pos','basic')))
M <- lmer(log(seek_resp.rt)~exp_pos*basic+(1|participant),data=clean_df)
summary(M)
plot(ggpredict(M,terms=c('exp_pos','basic')))
M <- lmer(log(seek_resp.rt)~exp_pos*basic+(1|participant),data=clean_df)
summary(M)
plot(ggpredict(M,terms=c('exp_pos','basic')))
ggsave(pred)
pred <- plot(ggpredict(M,terms=c('exp_pos','basic')))
ggsave(pred)
plot(ggpredict(M,terms=c('exp_pos','basic')))
knitr::opts_chunk$set(warnings = FALSE,
message=FALSE) #echo is usually set to true by default... this chunk will not be included
#in analysis
knitr::opts_knit$set(root.dir = "~/Desktop")
library(tidyverse)
library(dplyr)
library(lme4)
library(ggeffects)
library(lmerTest)
library(Hmisc)
datafiles <- lapply(Sys.glob("~/Documents/GitHub/scene_attn/analysis/data_RT/data*.csv"), read_csv) #makes a list of all the raw datafiles that match the pattern 'data*.csv'.
clean_data <- list()
for (i in datafiles) #begin loop
{
dat_vars <- i %>% #pipe for each iteration of the loop, where i = a member of "datafiles"
select('img', 'basic', 'seek_resp.corr', 'seek_resp.rt', 'slow_resp.started', 'condition', 'participant') #select these columns
dat_vars <- na.omit(dat_vars) #eliminates the extra two rows for each image
#dat_vars <- subset(dat_vars, slow_resp.started=='None') #we will not count timed-out responses
this_list <- assign(paste("data_", dat_vars[5:5,7], sep = ""), dat_vars) # assign the name to the new dataframe
clean_data <- append(clean_data,list(this_list)) #add to clean_data list
}
clean_df <- do.call(rbind,clean_data) #makes a single dataframe containing all teh called-in and cleaned data
#example
# clean_df %>% group_by(participant) %>% summarise(mgood=length(seek_resp.corr)/120) #the number of responses that the participants made on time.
#remove unnecessary variables
rm(clean_data)
rm(dat_vars)
rm(i)
rm(this_list)
tags <- c("stage_1", "stage_2","stage_3", "stage_4", "stage_5", "stage_6", "stage_7", "stage_8", "stage_9", "stage_10")
#clean_df %>% group_by(participant) %>% count() why is this here? I do not know
clean_df <- clean_df %>% group_by(participant) %>% mutate(exp_pos = 1:n())
clean_df <- clean_df%>% mutate(rt_bins=case_when(
exp_pos <12 ~ tags[1],
exp_pos >=12 & exp_pos <24 ~ tags[2],
exp_pos >=24 & exp_pos <36 ~ tags[3],
exp_pos >=36 & exp_pos <48 ~ tags[4],
exp_pos >=48 & exp_pos <60 ~ tags[5],
exp_pos >=60 & exp_pos <72 ~ tags[6],
exp_pos >=72 & exp_pos <84 ~ tags[7],
exp_pos >=84 & exp_pos <96 ~ tags[8],
exp_pos >=96 & exp_pos <108 ~ tags[9],
exp_pos >=108 & exp_pos <120 ~ tags[10]
))
#clean_df <- subset(clean_df, seek_resp.corr==1) #removes incorrect responses
clean_df$basic[clean_df$basic=='r_city_street'] <- 'city_street' #renames variable
clean_df$basic[clean_df$basic=='r_forest'] <- 'forest' #renames variable
clean_df %>% group_by(participant) %>% summarise(medianRT=(median(seek_resp.rt)))
clean_df %>% group_by (participant, basic) %>% summarise(medianRT=median(seek_resp.rt))
median_rt_bins <- clean_df %>% group_by(participant, rt_bins) %>% summarise(medianRT=median(seek_resp.rt))
ggplot(median_rt_bins, aes(x=rt_bins, y=medianRT))+ geom_point() + labs(x="Stages") + scale_y_log10() + facet_wrap(~participant)
M <- lmer(log(seek_resp.rt)~exp_pos*basic+(1|participant),data=clean_df)
summary(M)
plot(ggpredict(M,terms=c('exp_pos','basic')))
dodge <- position_dodge(0.8)
ggplot(clean_df,aes(x=factor(rt_bins),y=seek_resp.rt,colour=condition,fill=condition))+
geom_dotplot(method='histodot',stackdir='center',binaxis='y',
binwidth=0.02,position=dodge,alpha=0.5)+
stat_summary(fun.data='mean_cl_boot',geom='errorbar',size=1,width=0.2,position=dodge)+
stat_summary(fun.data='mean_cl_boot',geom='point',size=3,position=dodge)+
ylab("correct RT (s)")+xlab('lag (trials)')
knitr::opts_chunk$set(warnings = FALSE,
message=FALSE) #echo is usually set to true by default... this chunk will not be included
#in analysis
knitr::opts_knit$set(root.dir = "~/Desktop")
dat <- read.csv('/Documents/Dropped/Courses/Stats_I/hw/final_4_data.csv')
dat <- read.csv('~/Documents/Dropped/Courses/Stats_I/hw/final_4_data.csv')
View(dat)
M <- lm(dat)
summary(M)
View(M)
M <- lmer(dat)
#a
dat <- read.csv('~/Documents/Dropped/Courses/Stats_I/hw/final_4_data.csv')
#b
#c
#d
#e
#f
View(dat)
library(tidyverse)
dat$behavior2z <- scale(dat$behavior2)
library(readr)
dat <- read_csv("C:/Users/cunni/Dropbox/classes_2016/GLM_2017/regressionData.csv")
View(dat)
cormat <- cor(dat)
View(dat)
t <- lm(score ~ note_taking + reading_notes)
View(dat)
t <- lm(dat$score ~ dat$note_taking + dat$reading_notes)
summary(t)
View(dat)
t <- lm(dat$score ~ dat$note_taking + dat$reading_notes+dat$int)
summary(t)
dat <- read.csv('~/Documents/Dropped/Courses/Stats_I/hw/final_4_data.csv')
t <- lm(dat$score ~ dat$note_taking + dat$reading_notes)
summary(t)
t <- lm(dat$score ~ dat$note_taking + dat$reading_notes +dat$int)
summary(t)
library(tidyverse)
dat <- read.csv('~/Documents/Dropped/Courses/Stats_I/hw/final_4.csv')
View(dat)
View(dat)
View(dat)
dat <- dat %>% mutate(
GM <- mean(score),
XGM <- score-GM,
XGM2 <- XGM*XGM
)
View(dat)
dat <- dat %>% mutate(
GM = mean(score),
XGM = score-GM,
XGM2  XGM*XGM
dat <- dat %>% mutate(
GM = mean(score),
XGM = score-GM,
XGM2 = XGM*XGM
)
dat <- read.csv('~/Documents/Dropped/Courses/Stats_I/hw/final_4.csv')
dat <- dat %>% mutate(
GM = mean(score),
XGM = score-GM,
XGM2 = XGM*XGM
)
View(dat)
View(dat)
gross_group <- dat$sbj[1:25]
gross_group <- dat$score[1:25]
gross_group <- dat$score[1:25]
yummy_group <- dat$score[26:50]
tasty_group <- dat$score[51:75]
yucky_group <- dat$score[76:100]
gross_group <- dat[1:25]
gross_group <- dat[1:10,1:25]
gross_group <- dat[1:25,1:10]
yummy_group <- dat[26:50,1:10]
tasty_group <- dat[51:75,1:10]
yucky_group <- dat[76:100,1:10]
View(tasty_group)
dat <- read.csv('~/Documents/Dropped/Courses/Stats_I/hw/final_4.csv')
gross_group <- dat[1:25,1:10]
dat <- dat %>% mutate(
GM = mean(score),
XGM = score-GM,
XGM2 = XGM*XGM
)
gross_group <- dat[1:25,1:10]
yummy_group <- dat[26:50,1:10]
tasty_group <- dat[51:75,1:10]
yucky_group <- dat[76:100,1:10]
gM_gross <- mean(gross_group$score)
gM_yummy <- mean(yummy_group$score)
gM_tasty <- mean(tasty_group$score)
gM_yucky <- mean(yucky_group$score)
View(gross_group)
View(tasty_group)
View(yucky_group)
SSTot <- sum(dat$XGM2)
gross_group <- dat[1:25,1:10]
gross_group <- gross_group %>% mutate(
gM <- mean(score),
e_gross <- score-gM,
e2_gross <- e_gross*e_gross
)
View(gross_group)
dat <- read.csv('~/Documents/Dropped/Courses/Stats_I/hw/final_4.csv')
dat <- dat %>% mutate(
GM = mean(score),
XGM = score-GM,
XGM2 = XGM*XGM
)
gross_group <- dat[1:25,1:10]
gross_group <- gross_group %>% mutate(
gM = mean(score),
e_gross = score-gM,
e2_gross = e_gross*e_gross
)
yummy_group <- dat[26:50,1:10]
yummy_group <- yummy_group %>% mutate(
gM = mean(score),
e_yummy = score-gM,
e2_yummy = e_yummy*e_yummy
)
tasty_group <- dat[51:75,1:10]
tasty_group <- tasty_group %>% mutate(
gM = mean(score),
e_tasty = score-gM,
e2_tasty = e_tasty*e_tasty
)
yucky_group <- dat[76:100,1:10]
yucky_group <- yucky_group %>% mutate(
gM = mean(score),
e_yucky = score-gM,
e2_yucky = e_yucky*e_yucky
)
SSTot <- sum(dat$XGM2)
View(yucky_group)
View(yummy_group)
dat <- read.csv('~/Documents/Dropped/Courses/Stats_I/hw/final_4.csv')
dat <- dat %>% mutate(
GM = mean(score),
XGM = score-GM,
XGM2 = XGM*XGM
)
N <- nrow(dat$sbj)
dfTot <- N-1
SSTot <- sum(dat$XGM2)
View(dat)
N <- NROW(dat$sbj)
dfTot <- N-1
SSTot <- sum(dat$XGM2)
gross_group <- dat[1:25,1:10]
gross_group <- gross_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e_gross*e_gross,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 <- gmGM*gmGM
)
gross_group <- dat[1:25,1:10]
gross_group <- gross_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e*e,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 <- gmGM*gmGM
)
yummy_group <- dat[26:50,1:10]
yummy_group <- yummy_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e*e,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 <- gmGM*gmGM
)
tasty_group <- dat[51:75,1:10]
tasty_group <- tasty_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e*e,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 <- gmGM*gmGM
)
yucky_group <- dat[76:100,1:10]
yucky_group <- yucky_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e*e,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 <- gmGM*gmGM
)
View(gross_group)
dat <- read.csv('~/Documents/Dropped/Courses/Stats_I/hw/final_4.csv')
dat <- dat %>% mutate(
GM = mean(score),
XGM = score-GM,
XGM2 = XGM*XGM
)
N <- NROW(dat$sbj)
dfTot <- N-1
SSTot <- sum(dat$XGM2)
gross_group <- dat[1:25,1:10]
gross_group <- gross_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e*e,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 = gmGM*gmGM
)
yummy_group <- dat[26:50,1:10]
yummy_group <- yummy_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e*e,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 = gmGM*gmGM
)
tasty_group <- dat[51:75,1:10]
tasty_group <- tasty_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e*e,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 = gmGM*gmGM
)
yucky_group <- dat[76:100,1:10]
yucky_group <- yucky_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e*e,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 = gmGM*gmGM
)
SSBetween <- (gross_group$gmGM2)+(tasty_group$gmGM2)+(yummy_group$gmGM2)+(yucky_group$gmGM2)
SSWithin <- (gross_group$e2)+(tasty_group$e2)+(yummy_group$e2)+(yucky_group$e2)
dfBetween <- 3
dfWithin <- 96
MSBetween <- SSBetween/dfBetween
MSWithin <- SSWithin/dfWithin
F <- MSBetween/MSWithin
dat <- read.csv('~/Documents/Dropped/Courses/Stats_I/hw/final_4.csv')
dat <- dat %>% mutate(
GM = mean(score),
XGM = score-GM,
XGM2 = XGM*XGM
)
N <- NROW(dat$sbj)
dfTot <- N-1
SSTot <- sum(dat$XGM2)
gross_group <- dat[1:25,1:10]
gross_group <- gross_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e*e,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 = gmGM*gmGM
)
yummy_group <- dat[26:50,1:10]
yummy_group <- yummy_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e*e,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 = gmGM*gmGM
)
tasty_group <- dat[51:75,1:10]
tasty_group <- tasty_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e*e,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 = gmGM*gmGM
)
yucky_group <- dat[76:100,1:10]
yucky_group <- yucky_group %>% mutate(
gM = mean(score),
e = score-gM,
e2 = e*e,
df = NROW(sbj)-1,
gmGM = gM-GM,
gmGM2 = gmGM*gmGM
)
SSBetween <- (sum(gross_group$gmGM2))+(sum(tasty_group$gmGM2))+(sum(yummy_group$gmGM2))+(sum(yucky_group$gmGM2))
SSWithin <- (sum(gross_group$e2))+(sum(tasty_group$e2)+(sum(yummy_group$e2))+(sum(yucky_group$e2))
SSWithin <- (sum(gross_group$e2))+(sum(tasty_group$e2))+(sum(yummy_group$e2))+(sum(yucky_group$e2))
SSWithin <- (sum(gross_group$e2))+(sum(tasty_group$e2))+
(sum(yummy_group$e2))+(sum(yucky_group$e2))
dfBetween <- 3
dfWithin <- 96
MSBetween <- SSBetween/dfBetween
MSWithin <- SSWithin/dfWithin
F <- MSBetween/MSWithin
F_val<- MSBetween/MSWithin
View(dat)
View(dat)
View(dat)
View(gross_group)
setwd("~/Documents/GitHub/psy_grad_coding/ps9-j-adema")
library(tidyverse)
# load in the data
ipip <- read_csv('ipip50_sample.csv')
# This dataset includes measures of the Big 5 Inventory personality index, which
# measures traits of Agreeableness, Conscientiousness, Extroversion,
# Neuroticism, and Openness, along with measures of age, BMI, and exercise
# habits for 1000 participants.
#
# In the dataset, each trait has a set of associated survey items (e.g.,
# Agreeableness has A_1, A_2, A_3, ... A_10). The total number of  items
# vary for the different traits (e.g., Agreeableness has 10, but Openness only
# has 2). For each participant, there are measures for each of the items as well
# as the participant's age, BMI, gender, and exercise habits which are
# categorically coded in terms of frequency.
#
# In this PS, we want to look at the relationship between the big 5 and age,
# gender, BMI, and exercise habits. To do so will require some data wrangling...
# Calculate composites of the big 5 ---------------------------------------
# Composites for the big 5 are based on the average value of their multiple
# items. For example, an Agreeableness composite would be the average of items
# A_1 through A_10. We want to calculate these averages for each trait
# separately for each participant. Do this by filling in the steps below:
# The data is in wide format (i.e., each row is separate participant with
# columns for different measures) and we need it in long format. Convert
# to long format with a gather command on the trait items (A_1...O_10):
# **HINT: The long format data set should have 42000 rows**
ipip.l <- ipip %>%
gather(key="key",value="value",A_1:O_10)
# We need a column that identifies rows as belonging to a specific trait,
# but the column you created based on the trait items includes both trait
# and item (e.g., A_1, but we want A in a separate column from item 1).
# Make this happen with a separate command:
ipip.l <- ipip.l %>%
separate(key, into=c('trait','level'),sep="_")
# Calculate averages for each participant (coded as RID) and trait:
ipip.comp <- ipip.l %>%
group_by(RID, trait) %>% mutate(count=n()) %>%
summarise(average = sum(value)/first(count))
# Cleaning up the other variables -----------------------------------------
# Depending on how you solved the above steps, your ipip.comp ttibble may or may
# not have the age, gender, exer, BMI variables that we want to compare to the big 5. If
# they are missing, let's add them in by joining the original ipip tibble with
# ipip.comp tibble:
# HINT: use a select call on ipip to only select the columns that you want to
# merge with ipip.comp
ipip.comp <- ipip %>%
select(RID, age,BMI,gender,exer) %>%
inner_join(ipip.comp)
# One last thing, our exercise variable is all out of order. Because it was read
# in as a character string, it is in alphabetical order. Let's turn it into a
# factor and reorder the levels according to increasing frequency. Do this by
# using the factor command and its levels argument:
ipip.comp$exer <- factor(ipip.comp$exer, ordered=TRUE, levels=c('veryRarelyNever',
'less1mo', 'less1wk', '1or2wk','3or5wk','more5wk'))
# Analyze the data! -------------------------------------------------------
# Summarise the trait values across the different levels of exercise habits.
# Calculate both the mean (use the new variable name 'avg') and standard error
# of the mean (i.e., standard deviation divided by the square root of the
# number of participants; use variable name 'sem'):
exer.avg <- ipip.comp %>%
group_by(exer,trait) %>%
summarise(avg = mean(average),
sem = sd(average)/sqrt(length(average)-1))
# If you properly created the exer.avg tibble above, the following code will
# create a plot and save it as figures/exer.pdf. Check your figure with
# figures/exer_answer.pdf to see if your data wrangling is correct!
dodge <- position_dodge(0.5)
ggplot(exer.avg,aes(x=trait,y=avg,colour=exer))+
geom_pointrange(aes(ymin=avg-sem,ymax=avg+sem),
position=dodge)+
labs(x='big 5 trait',y='mean trait value',title='Big 5 and exercise')
ggsave('figures/exer.pdf',units='in',width=7,height=5)
# repeat the above summary commands for gender:
gender.avg <- ipip.comp %>%
group_by(gender,trait) %>% summarise(avg = mean(average),
sem = sd(average)/sqrt(length(average)-1))
# create a gender plot and compare to the answer figure:
ggplot(gender.avg,aes(x=trait,y=avg,colour=gender))+
geom_pointrange(aes(ymin=avg-sem,ymax=avg+sem),
position=dodge)+
labs(x='big 5 trait',y='mean trait value',title='Big 5 and gender')
ggsave('figures/gender.pdf',units='in',width=5,height=5)
# For BMI, we need to recode the BMI continuous values into a categorical
# variable. Add a new BMI_cat variable to ipip.comp based on common definitions
# of BMI categories:
# <18.5=underweight, 18.5-25=healthy, 25-30=overweight, >30=obese
# HINT: check out the case_when function:
#     https://dplyr.tidyverse.org/reference/case_when.html
ipip.comp <- ipip.comp %>%
mutate(BMI_cat = case_when(
BMI <18.5 ~ 'underweight',
BMI >18.5 & BMI<25 ~ 'healthy',
BMI >25 & BMI<30 ~ 'overweight',
BMI >30 ~ 'obese'))
# turn BMI_cat into a factor and order it with levels
ipip.comp$BMI_cat <- factor(ipip.comp$BMI_cat,ordered=TRUE,
levels=c('underweight','healthy','overweight','obese'))
# summarise trait values by BMI categories
bmi.avg <- ipip.comp %>%
group_by(BMI_cat,trait) %>% summarise(avg = mean(average),
sem = sd(average)/sqrt(length(average)-1))
# create BMI plot and compare to the answer figure:
ggplot(bmi.avg,aes(x=trait,y=avg,colour=BMI_cat))+
geom_pointrange(aes(ymin=avg-sem,ymax=avg+sem),
position=dodge)+
labs(x='big 5 trait',y='mean trait value',title='Big 5 and BMI')
ggsave('figures/BMI.pdf',units='in',width=7,height=5)
age.avg <- ipip.comp %>%
group_by(trait)%>%
summarise(corrcoef=cor(age,meanscore))
age.avg <- ipip.comp %>%
group_by(trait)%>%
summarise(corrcoef=cor(age,average))
ggplot(age.avg,aes(x=trait,y=corrcoef))+
geom_hline(yintercept=0)+
geom_point(size=3)+
labs(x='big 5 trait',y='correlation between trait and age',title='Big 5 and age')
ggsave('figures/age.pdf',units='in',width=4,height=5)
